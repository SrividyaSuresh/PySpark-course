{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6de2628c-1b31-4cf8-bfb7-e7748f5034a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# PySpark RDDs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8aabc90f-b23f-4818-ac48-80cbfb4affec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "On Databricks, on creating a cluster, the SparkSession is created internally. SparkConf, SparkContext or SQLContext, don't have to be called explicitly as they are encapsulated inside SparkSession, accessible through a variabled called spark. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9b1803c-afe7-47ef-9d7e-a02d6e099b72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=2127845047214380#setting/sparkui/0717-171046-zcous302/driver-6783164060441475523\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=2127845047214380#setting/sparkui/0717-171046-zcous302/driver-6783164060441475523\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13c51502-943e-4d28-bd6d-9d993d15130e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "If this is run through Jupyter notebook or as python wheel file, it needs to be initialised, conventionally like this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d655b66-9942-4bba-9c4e-73ccab26163b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Intro').getOrCreate() # app name can be changed, ofc.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Json file handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"/FileStore/tables/oscar-2.json\",multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- awards: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------+------------------+----+\n",
      "|              awards|            director|         genre|             title|year|\n",
      "+--------------------+--------------------+--------------+------------------+----+\n",
      "|[Best Picture, Be...|        Bong Joon-ho|Drama/Thriller|          Parasite|2019|\n",
      "|[Best Picture, Be...|  Guillermo del Toro| Drama/Fantasy|The Shape of Water|2017|\n",
      "|[Best Picture, Be...|       Barry Jenkins|         Drama|         Moonlight|2016|\n",
      "|[Best Picture, Be...|        Tom McCarthy|         Drama|         Spotlight|2015|\n",
      "|[Best Picture, Be...|Alejandro G. I침치r...|  Drama/Comedy|           Birdman|2014|\n",
      "+--------------------+--------------------+--------------+------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[13]: ['awards', 'director', 'genre', 'title', 'year']"
     ]
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------+------------------+------------------+\n",
      "|summary|            director|         genre|             title|              year|\n",
      "+-------+--------------------+--------------+------------------+------------------+\n",
      "|  count|                   5|             5|                 5|                 5|\n",
      "|   mean|                null|          null|              null|            2016.2|\n",
      "| stddev|                null|          null|              null|1.9235384061671172|\n",
      "|    min|Alejandro G. I침치r...|         Drama|           Birdman|              2014|\n",
      "|    max|        Tom McCarthy|Drama/Thriller|The Shape of Water|              2019|\n",
      "+-------+--------------------+--------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Spark Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schema = StructType([\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"genre\", StringType(), True),\n",
    "    StructField(\"director\", StringType(), True),\n",
    "    StructField(\"year\", IntegerType(), True),\n",
    "    StructField(\"awards\", ArrayType(StringType(), True), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- awards: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json(\"/FileStore/tables/oscar-2.json\",multiLine=True, schema=df_schema)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV File handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/FileStore/tables/titanic.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic RDD functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5207108-0446-4a07-a74f-2fc20472d263",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10daeb3e-a928-438f-bac4-27e39d272d35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2024-07-17 17:21:11",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
